{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae2ef0d2-0c53-45d3-9b2f-281ac1bcd43d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Claude + Genie を使用したエージェントシステム(Mosaic AI Agent Framework)\n",
    "\n",
    "このノートブックでは、Mosaic AI Agent Framework と [LangGraph](https://blog.langchain.dev/langgraph-multi-agent-workflows/) を使用してマルチエージェントシステムを構築する方法を説明します。ここで、[Genie](https://www.databricks.com/product/ai-bi/genie) はエージェントの 1 つです。またSupervisortとしてDatabricks内で利用可能な[AnthropicのClaude](https://www.databricks.com/jp/blog/anthropic-claude-37-sonnet-now-natively-available-databricks)を採用しております。\n",
    "このノートブックでは、以下の操作を行います。\n",
    "1. LangGraph を使用してマルチエージェントシステムを作成します。\n",
    "1. Databricks の機能との互換性を確保するために、LangGraph エージェントを MLflow の `ChatAgent` でラップします。\n",
    "1. マルチエージェントシステムの出力を手動でテストします。\n",
    "1. マルチエージェントシステムのログを取得し、デプロイします。\n",
    "\n",
    "この例は、[LangGraph ドキュメント - マルチエージェント スーパーバイザーの例](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/multi_agent/agent_supervisor.ipynb)を基にしています。\n",
    "\n",
    "## Claudeとは\n",
    "\n",
    "Claude 3.7 Sonnetは、Anthropicがこれまでに開発した中で最も高度なAIモデルです。複雑な推論やマルチステップの計画立案、長い文脈を伴う対話、文書やデータの深い理解といった高度なタスクにおいて、業界トップクラスの性能を発揮します。Claude 3.7 Sonnetが、AWS・Azure・GCP上のDatabricksでネイティブに利用可能になりました。推論・計画・エージェントタスクに特化したAnthropicの最先端モデルに、安全かつガバナンスの効いた形でアクセスできます。\n",
    "\n",
    "## Genie エージェントを使用する理由\n",
    "\n",
    "マルチエージェントシステムは、それぞれに専門能力を持つ複数のAIエージェントで構成されています。Genieは、そのエージェントの1つであり、ユーザーが自然言語を使用して構造化データとやりとりすることを可能にします。\n",
    "\n",
    "あらかじめ定義されたクエリのみを実行できるSQL関数とは異なり、Genieはユーザーの質問に答えるために新しいクエリを作成できる柔軟性があります。\n",
    "\n",
    "## 前提条件\n",
    "\n",
    "- このノートブック内のすべての「TODO」を処理する。(Genie SPACE ID/ PAT / Modelを保存するCatalog)\n",
    "- Genie Spaceを作成します。Databricksのドキュメントを参照してください（[AWS](https://docs.databricks.com/aws/genie/set-up) | [Azure](https://learn.microsoft.com/azure/databricks/genie/set-up))。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fad5bdf5-8ab6-40ad-8b7f-71589b07dde4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqq mlflow langgraph==0.3.4 databricks-langchain databricks-agents uv\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d402207-8884-456d-8e29-dce582e48dd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## マルチエージェントシステムを定義する\n",
    "\n",
    "LangGraphで、以下のエージェントノードを指示するスーパーバイザーエージェントノードを使用してマルチエージェントシステムを作成します。\n",
    "- **GenieAgent**: 構造化データに対してクエリーを実行し、推論を行うGenieエージェント。\n",
    "- **Tool-calling agent**: Unityカタログ機能ツールを呼び出すエージェント。(今回のノートブックでは利用しません)\n",
    "\n",
    "LangGraph エージェントを `ChatAgent` インターフェイスでラップする\n",
    "\n",
    "Databricks では、Databricks の AI 機能との互換性を確保し、オープンソース標準を使用して複数ターン型の会話型エージェントの作成を簡略化するために、`ChatAgent` の使用を推奨しています。 \n",
    "\n",
    "LangGraphChatAgent` クラスは、LangGraph エージェントをラップするために `ChatAgent` インターフェイスを実装します。\n",
    "\n",
    "MLflowの[ChatAgentドキュメント](https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#mlflow.pyfunc.ChatAgent)を参照してください。\n",
    "\n",
    "エージェントコードをファイルに書き込む\n",
    "\n",
    "以下の単一セルでエージェントコードを定義します。これにより、`%%writefile`マジックコマンドを使用して、エージェントコードをローカルPythonファイルに書き込むことができ、その後のログ取得やデプロイに使用できます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f3dd3fe-eec2-4a73-b025-2340aa192afb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "genie_agent_description = \"This agent can answer questions about data. but please use only one\"\n",
    "#code_agent_description = \"今回は利用しません\"\n",
    "worker_descriptions = {\n",
    "    \"Genie\": genie_agent_description,\n",
    "    #\"Coder\": code_agent_description,   #このデモでは、Coderを利用せずGenie のみをAgentとして利用するため外しておきます。\n",
    "}\n",
    "\n",
    "formatted_descriptions = \"\\n\".join(\n",
    "    f\"- {name}: {desc}\" for name, desc in worker_descriptions.items()\n",
    ")\n",
    "print(formatted_descriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a89ad7a6-599d-46a9-9f09-b149e4651c87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile agent.py\n",
    "import functools\n",
    "import os\n",
    "from typing import Any, Generator, Literal, Optional\n",
    "\n",
    "import mlflow\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from databricks_langchain.genie import GenieAgent\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "from pydantic import BaseModel\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "###################################################\n",
    "## Create a GenieAgent with access to a Genie Space\n",
    "###################################################\n",
    "\n",
    "# TODO add GENIE_SPACE_ID and a description for this space\n",
    "GENIE_SPACE_ID = \"01efbd0fe8711ecd80e48dcbc4042f28\"\n",
    "genie_agent_description = \"This agent can answer questions about user's inquiry data.\"\n",
    "\n",
    "genie_agent = GenieAgent(\n",
    "    genie_space_id=GENIE_SPACE_ID,\n",
    "    genie_agent_name=\"Genie\",\n",
    "    description=genie_agent_description,\n",
    "    # DB_MODEL_SERVING_HOST_URL is set on an agent endpoints but doesn't exist in the notebook\n",
    "    client=WorkspaceClient(\n",
    "        host=os.getenv(\"DATABRICKS_HOST\") or os.getenv(\"DB_MODEL_SERVING_HOST_URL\"),\n",
    "        token=os.getenv(\"DATABRICKS_GENIE_PAT\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "\n",
    "# TODO: Replace with your model serving endpoint, multi-agent Genie works best with GPT 4o and GPT o1 models.\n",
    "#LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-1-405b-instruct\"\n",
    "LLM_ENDPOINT_NAME = \"databricks-claude-3-7-sonnet\"\n",
    "\n",
    "assert LLM_ENDPOINT_NAME is not None\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "\n",
    "############################################################\n",
    "# Create a code agent\n",
    "# You can also create agents with access to additional tools\n",
    "# 今回は利用しないため、スキップしてください\n",
    "############################################################\n",
    "client = DatabricksFunctionClient()\n",
    "set_uc_function_client(client)\n",
    "\n",
    "tools = []\n",
    "\n",
    "# TODO if desired, add additional tools and update the description of this agent. \n",
    "uc_tool_names = [\"system.ai.*\"]\n",
    "uc_toolkit = UCFunctionToolkit(function_names=uc_tool_names)\n",
    "tools.extend(uc_toolkit.tools)\n",
    "code_agent_description = (\n",
    "    \"The Coder agent specializes in solving programming challenges, generating code snippets, debugging issues, and explaining complex coding concepts.\",\n",
    ")\n",
    "code_agent = create_react_agent(llm, tools=tools)\n",
    "\n",
    "#############################\n",
    "# Define the supervisor agent\n",
    "#############################\n",
    "\n",
    "worker_descriptions = {\n",
    "    \"Genie\": genie_agent_description,\n",
    "    #\"Coder\": code_agent_description,\n",
    "}\n",
    "\n",
    "formatted_descriptions = \"\\n\".join(\n",
    "    f\"- {name}: {desc}\" for name, desc in worker_descriptions.items()\n",
    ")\n",
    "\n",
    "#system_prompt = f\"Decide between routing between the following workers or ending the conversation if an answer is provided. You shouldn't repeat Genie. please finish it after the first worker. \\n{formatted_descriptions}\"\n",
    "system_prompt = f\"Decide between routing between the following workers or ending the conversation if an answer is provided. Genieに問い合わせる際にはSQLでデータを取得しやすいような質問に変換して投げてください。データ内容から判断するような命令は投げないで、最後にSupvissorが回答してください。またGenieから返ってきたデータを繰り返しGenieに質問として投げないでください。Genieへのルーティングは１っ回だけとし、もしGenieからデータが返ってこない場合、ユーザーに質問を返しFinishを選択してください\"\n",
    "\n",
    "\n",
    "options = [\"FINISH\"] + list(worker_descriptions.keys())\n",
    "\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    class nextNode(BaseModel):\n",
    "        next_node: Literal[tuple(options)]\n",
    "\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    )\n",
    "    supervisor_chain = preprocessor | llm.with_structured_output(nextNode)\n",
    "    return supervisor_chain.invoke(state)\n",
    "\n",
    "\n",
    "\n",
    "#######################################\n",
    "# Define our multiagent graph structure\n",
    "#######################################\n",
    "\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [\n",
    "        #\"messages\": state[\"messages\"] + [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": result[\"messages\"][-1].content,\n",
    "                \"name\": name,\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def final_answer(state):\n",
    "    system_prompt = \"Using only the content in the messages, respond to the user's question using the answer given by the other agents.\"\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    )\n",
    "    final_answer_chain = preprocessor | llm\n",
    "    return {\"messages\": [final_answer_chain.invoke(state)]}\n",
    "\n",
    "\n",
    "class AgentState(ChatAgentState):\n",
    "    next_node: str\n",
    "\n",
    "\n",
    "code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
    "genie_node = functools.partial(agent_node, agent=genie_agent, name=\"Genie\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Genie\", genie_node)\n",
    "workflow.add_node(\"Coder\", code_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)\n",
    "workflow.add_node(\"final_answer\", final_answer)\n",
    "\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "# We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "for worker in worker_descriptions.keys():\n",
    "    workflow.add_edge(worker, \"supervisor\")\n",
    "\n",
    "# Let the supervisor decide which next node to go\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda x: x[\"next_node\"],\n",
    "    {**{k: k for k in worker_descriptions.keys()}, \"FINISH\": \"final_answer\"},\n",
    ")\n",
    "workflow.add_edge(\"final_answer\", END)\n",
    "multi_agent = workflow.compile()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "# Wrap our multi-agent in ChatAgent\n",
    "###################################\n",
    "\n",
    "\n",
    "class LangGraphChatAgent(ChatAgent):\n",
    "    def __init__(self, agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        request = {\n",
    "            \"messages\": [m.model_dump_compat(exclude_none=True) for m in messages]\n",
    "        }\n",
    "\n",
    "        messages = []\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                messages.extend(\n",
    "                    ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n",
    "                )\n",
    "        return ChatAgentResponse(messages=messages)\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        request = {\n",
    "            \"messages\": [m.model_dump_compat(exclude_none=True) for m in messages]\n",
    "        }\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                yield from (\n",
    "                    ChatAgentChunk(**{\"delta\": msg})\n",
    "                    for msg in node_data.get(\"messages\", [])\n",
    "                )\n",
    "\n",
    "\n",
    "# Create the agent object, and specify it as the agent object to use when\n",
    "# loading the agent back for inference via mlflow.models.set_model()\n",
    "AGENT = LangGraphChatAgent(multi_agent)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0103f4c-4a1f-40ca-9f3d-28bcd1803ec2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the agent\n",
    "\n",
    "エージェントとやりとりして、その出力をテストします。このノートブックを `mlflow.langchain.autolog()` と呼ぶので、エージェントが実行する各ステップのトレースを表示できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11079f06-9837-4208-af79-2d910058cf2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a447d522-1c9c-4454-b1ed-fec2617e38a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create a Personal Access Token (PAT) as a Databricks secret\n",
    "Genie Spaceとそのリソースにアクセスするには、PATを作成する必要があります。\n",
    "- これは、お客様自身の PAT またはシステムプリンシパルの PAT（[AWS](https://docs.databricks.com/aws/en/dev-tools/auth/oauth-m2m) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/dev-tools/auth/oauth-m2m)）のいずれかです。有効期限が切れた場合は、お客様自身でこのトークンを更新する必要があります。\n",
    "- エンドポイントを提供するモデルに、秘密鍵ベースの環境変数を追加します。（[AWS](https://docs.databricks.com/aws/en/machine-learning/model-serving/store-env-variable-model-serving#add-secrets-based-environment-variables) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-serving/store-env-variable-model-serving#add-secrets-based-environment-variables))。\n",
    "- 各リソースの適切な権限レベルについては、デプロイドキュメントの表を参照してください。（[AWS](https://docs.databricks.com/aws/en/generative-ai/agent-framework/deploy-agent#automatic-authentication-passthrough) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/agent-framework/deploy-agent#automatic-authentication-passthrough))\n",
    "  - Genie Spaceに「CAN RUN」権限でプロビジョニング\n",
    "  - Genie Spaceを動かすSQL Warehouseに「CAN USE」権限でプロビジョニング\n",
    "  - Unity Catalogのテーブルに「SELECT」権限でプロビジョニング \n",
    "  - 基盤となるUnityカタログ関数に対する`EXECUTE`の提供 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d180a09-5243-4806-a7d3-e9a5664e730d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# TODO: set secret_scope_name and secret_key_name to access your PAT\n",
    "secret_scope_name = \"<Scope>\"\n",
    "secret_key_name = \"<Key>\"\n",
    "os.environ[\"DATABRICKS_GENIE_PAT\"] = dbutils.secrets.get(\n",
    "scope=secret_scope_name, key=secret_key_name\n",
    ")\n",
    "assert os.environ[\"DATABRICKS_GENIE_PAT\"] is not None, (\n",
    "    \"The DATABRICKS_GENIE_PAT was not properly set to the PAT secret\"\n",
    ")\n",
    "\n",
    "#os.environ[\"DATABRICKS_GENIE_PAT\"] = \"<PAT>\" #上記Sercetを使わず直接記載する場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a25c3cc5-f4b9-4b4f-b2f8-ca4776f33a44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**TODO**: このプレースホルダー `input_example` を、エージェント用のドメイン固有のプロンプトに置き換えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93f75405-f596-4d44-99d3-be114ef27127",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "input_example"
    }
   },
   "outputs": [],
   "source": [
    "from agent import AGENT\n",
    "\n",
    "input_example = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"2024年の月毎の問い合わせ数から傾向を分析して？\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "AGENT.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af022e19-a090-41fa-9c9a-d64c43ca334f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for event in AGENT.predict_stream(input_example):\n",
    "  print(event, \"-----------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "299790ba-cd17-4f11-babc-1bc6d3c18cc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log the agent as an MLflow model\n",
    "\n",
    "`agent.py` ファイルからエージェントをコードとしてログに記録します。 [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code) を参照してください。\n",
    "\n",
    "### Databricks リソースの自動認証を有効にする\n",
    "Databricks は、最も一般的な Databricks リソースタイプについては、ログ記録時に事前にエージェントのリソース依存関係を宣言することをサポートし、推奨しています。これにより、エージェントをデプロイした際に自動認証パススルーが有効になります。自動認証パススルーにより、Databricks はエージェントエンドポイント内からこれらのリソース依存関係に安全にアクセスするために、短時間で有効期限が切れる認証情報を自動的にプロビジョニング、ローテーション、および管理します。\n",
    "\n",
    "自動認証を有効にするには、`mlflow.pyfunc.log_model()` を呼び出す際に依存する Databricks リソースを指定します。\n",
    "  - **TODO**: Unity Catalog ツールが [ベクトル検索インデックス](docs link) を照会したり、[外部関数](docs link) を利用したりする場合は、依存するベクトル検索インデックスと UC 接続オブジェクトをそれぞれリソースとして含める必要があります。docsを参照（[AWS](https://docs.databricks.com/generative-ai/agent-framework/log-agent.html#specify-resources-for-automatic-authentication-passthrough) | [Azure](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/log-agent#resources)）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54a7fdf0-d9a1-4d5b-ab3e-2044da70eaa1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "import mlflow\n",
    "from agent import GENIE_SPACE_ID, LLM_ENDPOINT_NAME, tools\n",
    "from databricks_langchain import UnityCatalogTool, VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import (\n",
    "    DatabricksFunction,\n",
    "    DatabricksGenieSpace,\n",
    "    DatabricksServingEndpoint,\n",
    ")\n",
    "\n",
    "# TODO: Manually include underlying resources if needed. See the TODO in the markdown above for more information.\n",
    "resources = [\n",
    "    DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME),\n",
    "    DatabricksGenieSpace(genie_space_id=GENIE_SPACE_ID),\n",
    "]\n",
    "for tool in tools:\n",
    "    if isinstance(tool, VectorSearchRetrieverTool):\n",
    "        resources.extend(tool.resources)\n",
    "    elif isinstance(tool, UnityCatalogTool):\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        input_example=input_example,\n",
    "        pip_requirements=[\n",
    "            \"mlflow\",\n",
    "            \"langgraph==0.3.4\",\n",
    "            \"databricks-langchain\",\n",
    "            \"pydantic\",\n",
    "        ],\n",
    "        resources=resources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "136c836c-8344-4817-80cd-cfbc3f2df3d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pre-deployment agent validation\n",
    "エージェントを登録して展開する前に、[mlflow.models.predict()](https://mlflow.org/docs/latest/python_api/mlflow.models.html#mlflow.models.predict) API を使用して展開前のチェックを実行します。Databricks のドキュメントを参照してください。 ([AWS](https://docs.databricks.com/en/machine-learning/model-serving/model-serving-debug.html#validate-inputs) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-serving/model-serving-debug#before-model-deployment-validation-checks)).\"\n",
    "\n",
    "(注意：社内で実行すると、IP ACLに引っかかり失敗しました。ただしこの後のステップでモデルサービングエンドポイントからであれば実行可能です。そのためエラーは無視して次のステップに行ってくさい)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0aba434a-d6b5-4169-90b0-39b6557a5c6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data=input_example,\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53dcfac4-0816-4f74-bee6-559740a35235",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the model to Unity Catalog\n",
    "\n",
    "UnityカタログにMLflowモデルを登録するために、以下の `catalog`, `schema`, `model_name` を更新します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d10d68c-eaba-432b-a318-333774a999f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"<Catalog>\"\n",
    "schema = \"<Schema>\"\n",
    "model_name = \"<ModelName>\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3c48cf1-9901-4764-be98-99092ac4142d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "944439bd-53a5-4f8b-a2b2-0cad24b4e397",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "agents.deploy(\n",
    "    UC_MODEL_NAME,\n",
    "    uc_registered_model_info.version,\n",
    "    tags={\"endpointSource\": \"docs\"},\n",
    "    environment_vars={\n",
    "        \"DATABRICKS_GENIE_PAT\": f\"{{{{secrets/{secret_scope_name}/{secret_key_name}}}}}\"\n",
    "        # \"DATABRICKS_GENIE_PAT\": \"<PAT>\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c01c102-7010-487c-8a02-46f8e4883748",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n",
    "\n",
    "エージェントがデプロイされた後は、AI playgroundでチャットを行い、追加のチェックを行ったり、フィードバックを得るために組織内のSMEと共有したり、本番アプリケーションに組み込んだりすることができます。Databricksのドキュメントを参照してください（[AWS](https://docs.databricks.com/en/generative-ai/deploy-agent.html) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/deploy-agent))。"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "claude_genie_agent_demo",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
